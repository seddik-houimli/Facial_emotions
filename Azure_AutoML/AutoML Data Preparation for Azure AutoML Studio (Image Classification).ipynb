{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML for Images\n",
    "\n",
    "### Data Preparation for Azure AutoML (Image Classification Task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "> To use this notebook, **you will need to install the private preview package for AutoML for Images from the private index**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade \"azureml-train-core<0.1.1\" \"azureml-train-automl<0.1.1\" \"azureml-contrib-dataset<0.1.1\" --extra-index-url \"https://azuremlsdktestpypi.azureedge.net/automl_for_images_private_preview/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import urllib\n",
    "from zipfile import ZipFile\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(\"Python version =\", sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "print(\"Today =\", now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "print(\"You are using Azure ML version\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your local platform\n",
    "import platform,socket,re,uuid,json,psutil,logging\n",
    "\n",
    "def getSystemInfo():\n",
    "    try:\n",
    "        info={}\n",
    "        info['Platform']=platform.system()\n",
    "        info['Platform-release']=platform.release()\n",
    "        info['Platform-version']=platform.version()\n",
    "        info['Architecture']=platform.machine()\n",
    "        info['Hostname']=socket.gethostname()\n",
    "        info['IP-address']=socket.gethostbyname(socket.gethostname())\n",
    "        info['MAC-address']=':'.join(re.findall('..', '%012x' % uuid.getnode()))\n",
    "        info['Processor']=platform.processor()\n",
    "        info['RAM']=str(round(psutil.virtual_memory().total / (1024.0 **3)))+\" Go\"\n",
    "        return json.dumps(info)\n",
    "    except Exception as e:\n",
    "        logging.exception(e)\n",
    "\n",
    "json.loads(getSystemInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Workspace setup\n",
    "In order to train and deploy models in Azure ML, you will first need to set up a workspace.\n",
    "\n",
    "An [Azure ML Workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-azure-machine-learning-architecture#workspace) is an Azure resource that organizes and coordinates the actions of many other Azure resources to assist in executing and sharing machine learning workflows. In particular, an Azure ML Workspace coordinates storage, databases, and compute resources providing added functionality for machine learning experimentation, deployment, inference, and the monitoring of deployed models.\n",
    "\n",
    "> Create an Azure ML Workspace within your Azure subscription, or load an existing workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1617264529681
    }
   },
   "outputs": [],
   "source": [
    "subscription_id='tobereplaced'   \n",
    "resource_group='your-resource-group'   \n",
    "workspace_name='your-workspace-name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "try:\n",
    "   ws = Workspace(subscription_id = subscription_id, resource_group = resource_group, workspace_name = workspace_name)\n",
    "   ws.write_config()\n",
    "   print(\"OK\")\n",
    "except:\n",
    "   print(\"Error: Workspace not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.name, ws.resource_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Azure ML GPU Compute target setup\n",
    "**You will need to provide a [Compute Target](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#compute-target) that will be used for your AutoML model training.** <br><br>\n",
    "**AutoML models for image tasks require GPU SKUs and support NC and ND families.** We recommend using the NCsv3-series (with v100 GPUs) for faster training. Using a compute target with a multi-GPU VM SKU will leverage the multiple GPUs to speed up training. Additionally, setting up a compute target with multiple nodes will allow for faster model training by leveraging parallelism, when tuning hyperparameters for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1617264539968
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "\n",
    "cluster_name = \"gpu-cars-classif\"\n",
    "\n",
    "try:\n",
    "    compute_target = ws.compute_targets[cluster_name]\n",
    "    print('Found existing compute target.')\n",
    "except KeyError:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_NC6', #GPU cluster\n",
    "                                                           idle_seconds_before_scaledown=1800, #Time out\n",
    "                                                           min_nodes=0, \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "# Can poll for a minimum number of nodes and for a specific timeout.\n",
    "# If no min_node_count is provided, it will use the scale settings for the cluster.\n",
    "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute status\n",
    "compute_target.provisioning_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cluster information\n",
    "compute_target.get_status().serialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute VM size\n",
    "compute_target.vm_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of available compute clusters in your Azure ML workspace\n",
    "listcomputeservers = ws.compute_targets\n",
    "for list in listcomputeservers:\n",
    "    print(list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment Setup\n",
    "Create an [Experiment](https://docs.microsoft.com/azure/machine-learning/service/concept-azure-machine-learning-architecture#experiment) in your workspace to track your model training runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'FacialEmotionRecognition' #Name of your experimentation\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset with input Training Data\n",
    "In order to generate models for computer vision, you will need to bring in labeled image data as input for model training in the form of an AzureML Labeled Dataset. You can either use a Labeled Dataset that you have exported from a Data Labeling project, or create a new Labeled Dataset with your labeled training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - First you will need to upload the images that you just preprocessed locally to the azure studio workspace. To do so, you will need to upload the faceObjects folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Secondly, you will need to create a jsonl file used later on to generate your dataset. To do all this, run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of images files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, _, files in os.walk('.'):\n",
    "    print(\"Dir:\", root, \"with\", len(files), \"images files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the downloaded data to JSONL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = \"carsimages/\"\n",
    "\n",
    "train_validation_ratio = 5\n",
    "\n",
    "# Retrieving default datastore that got automatically created when we setup a workspace\n",
    "workspaceblobstore = ws.get_default_datastore().name\n",
    "\n",
    "# Path to the training and validation files\n",
    "train_annotations_file = os.path.join(src, \"train_annotations.jsonl\")\n",
    "validation_annotations_file = os.path.join(src, \"validation_annotations.jsonl\")\n",
    "\n",
    "# sample json line dictionary\n",
    "json_line_sample = \\\n",
    "    {\n",
    "        \"image_url\": \"AmlDatastore://\" + workspaceblobstore + \"/\"\n",
    "                     + os.path.basename(os.path.dirname(src)),\n",
    "        \"label\": \"\",\n",
    "        \"label_confidence\": 1.0\n",
    "    }\n",
    "\n",
    "index = 0\n",
    "# Scan each sub directary and generate jsonl line\n",
    "with open(train_annotations_file, 'w') as train_f:\n",
    "    with open(validation_annotations_file, 'w') as validation_f:\n",
    "        for className in os.listdir(src):\n",
    "            subDir = src + className\n",
    "            if not os.path.isdir(subDir):\n",
    "                continue\n",
    "            # Scan each sub directary\n",
    "            print(\"Parsing \" + subDir)\n",
    "            for image in os.listdir(subDir):\n",
    "                json_line = dict(json_line_sample)\n",
    "                json_line[\"image_url\"] += f\"/{className}/{image}\"\n",
    "                json_line[\"label\"] = className\n",
    "\n",
    "                if index % train_validation_ratio == 0:\n",
    "                    # validation annotation\n",
    "                    validation_f.write(json.dumps(json_line) + \"\\n\")\n",
    "                else:\n",
    "                    # train annotation\n",
    "                    train_f.write(json.dumps(json_line) + \"\\n\")\n",
    "                index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the JSONL file and images to Datastore  \n",
    "In order to use the data for training in Azure ML, we upload it to our Azure ML Workspace via a [Datastore](https://docs.microsoft.com/en-us/azure/machine-learning/concept-azure-machine-learning-architecture#datasets-and-datastores). The datastore provides a mechanism for you to upload/download data, and interact with it from your remote compute targets. It is an abstraction over Azure Storage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving default datastore that got automatically created when we setup a workspace\n",
    "ds = ws.get_default_datastore()\n",
    "ds.upload(src_dir='./faceObjects/', target_path='faceObjects')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need to create an Azure ML [Dataset](https://docs.microsoft.com/en-us/azure/machine-learning/concept-azure-machine-learning-architecture#datasets-and-datastores) from the data we uploaded to the Datastore. We create one dataset for training and one for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.contrib.dataset.labeled_dataset import _LabeledDatasetFactory, LabeledDatasetTask\n",
    "from azureml.core import Dataset\n",
    "\n",
    "training_dataset_name = 'FacialEmotionRecognitionTrainingDataset'\n",
    "if training_dataset_name in ws.datasets:\n",
    "    training_dataset = ws.datasets.get(training_dataset_name)\n",
    "    print('Found the training dataset', training_dataset_name)\n",
    "else:\n",
    "    # create training dataset\n",
    "    training_dataset = _LabeledDatasetFactory.from_json_lines(\n",
    "        task=LabeledDatasetTask.IMAGE_CLASSIFICATION, path=ds.path('faceObjects/train_annotations.jsonl'))\n",
    "    training_dataset = training_dataset.register(workspace=ws, name=training_dataset_name)\n",
    "    \n",
    "# create validation dataset\n",
    "validation_dataset_name = \"FacialEmotionRecognitionValidationDataset\"\n",
    "if validation_dataset_name in ws.datasets:\n",
    "    validation_dataset = ws.datasets.get(validation_dataset_name)\n",
    "    print('Found the validation dataset', validation_dataset_name)\n",
    "else:\n",
    "    validation_dataset = _LabeledDatasetFactory.from_json_lines(\n",
    "        task=LabeledDatasetTask.IMAGE_CLASSIFICATION, path=ds.path('faceObjects/validation_annotations.jsonl'))\n",
    "    validation_dataset = validation_dataset.register(workspace=ws, name=validation_dataset_name)\n",
    "\n",
    "print()\n",
    "print(\"Training dataset name:\" + training_dataset.name)\n",
    "print(\"Validation dataset name:\" + validation_dataset.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation dataset is optional. If no validation dataset is specified, by default 20% of your training data will be used for validation. You can control the percentage using the `split_ratio` argument - please refer to the documentation for more details.\n",
    "\n",
    "This is what the training dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=training_dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts images by labels\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage values\n",
    "df['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
